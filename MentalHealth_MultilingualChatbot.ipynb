{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Install Required Libraries**"
      ],
      "metadata": {
        "id": "jl4C87tMmLzK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZCkJGHLY83_",
        "outputId": "856dd5d2-1a6c-45b0-dcdc-28875acca668"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index\n",
            "  Downloading llama_index-0.12.36-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting llama-index-core\n",
            "  Downloading llama_index_core-0.12.36-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting llama-index-embeddings-huggingface\n",
            "  Downloading llama_index_embeddings_huggingface-0.5.4-py3-none-any.whl.metadata (458 bytes)\n",
            "Collecting pinecone\n",
            "  Downloading pinecone-6.0.2-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting llama-index-agent-openai<0.5,>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_agent_openai-0.4.7-py3-none-any.whl.metadata (438 bytes)\n",
            "Collecting llama-index-cli<0.5,>=0.4.1 (from llama-index)\n",
            "  Downloading llama_index_cli-0.4.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting llama-index-embeddings-openai<0.4,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl.metadata (684 bytes)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.6.11-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting llama-index-llms-openai<0.4,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_llms_openai-0.3.40-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.5,>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl.metadata (726 bytes)\n",
            "Collecting llama-index-program-openai<0.4,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_program_openai-0.3.1-py3-none-any.whl.metadata (764 bytes)\n",
            "Collecting llama-index-question-gen-openai<0.4,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl.metadata (783 bytes)\n",
            "Collecting llama-index-readers-file<0.5,>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_readers_file-0.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index) (3.9.1)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core) (3.11.15)\n",
            "Collecting aiosqlite (from llama-index-core)\n",
            "  Downloading aiosqlite-0.21.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting banks<3,>=2.0.0 (from llama-index-core)\n",
            "  Downloading banks-2.1.2-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting dataclasses-json (from llama-index-core)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core)\n",
            "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting dirtyjson<2,>=1.0.8 (from llama-index-core)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting filetype<2,>=1.2.0 (from llama-index-core)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core) (2025.3.2)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core) (0.28.1)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core) (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core) (11.2.1)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core) (2.11.4)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core) (2.32.3)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core) (2.0.40)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core) (9.1.2)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core) (4.13.2)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core) (1.17.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.31.2)\n",
            "Requirement already satisfied: sentence-transformers>=2.6.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-embeddings-huggingface) (4.1.0)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2025.4.26)\n",
            "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone)\n",
            "  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2.9.0.post0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2.4.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core) (1.20.0)\n",
            "Collecting griffe (from banks<3,>=2.0.0->llama-index-core)\n",
            "  Downloading griffe-1.7.3-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core) (3.1.6)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core) (4.3.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.18.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (24.2)\n",
            "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.78.1)\n",
            "Collecting llama-cloud<0.2.0,>=0.1.13 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud-0.1.21-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (4.13.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (2.2.2)\n",
            "Collecting pypdf<6.0.0,>=5.1.0 (from llama-index-readers-file<0.5,>=0.4.0->llama-index)\n",
            "  Downloading pypdf-5.5.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.5,>=0.4.0->llama-index)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.22-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (8.2.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (1.5.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core) (0.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core) (3.10)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (4.51.3)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.15.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core) (3.2.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core) (0.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2.7)\n",
            "Collecting llama-cloud-services>=0.6.22 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.22-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.3.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.5.3)\n",
            "Collecting colorama>=0.4 (from griffe->banks<3,>=2.0.0->llama-index-core)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->banks<3,>=2.0.0->llama-index-core) (3.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.6.0)\n",
            "Collecting llama-cloud<0.2.0,>=0.1.13 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud-0.1.19-py3-none-any.whl.metadata (902 bytes)\n",
            "Collecting python-dotenv<2.0.0,>=1.0.1 (from llama-cloud-services>=0.6.22->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Downloading llama_index-0.12.36-py3-none-any.whl (7.0 kB)\n",
            "Downloading llama_index_core-0.12.36-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_embeddings_huggingface-0.5.4-py3-none-any.whl (8.9 kB)\n",
            "Downloading pinecone-6.0.2-py3-none-any.whl (421 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m421.9/421.9 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading banks-2.1.2-py3-none-any.whl (28 kB)\n",
            "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading llama_index_agent_openai-0.4.7-py3-none-any.whl (14 kB)\n",
            "Downloading llama_index_cli-0.4.1-py3-none-any.whl (28 kB)\n",
            "Downloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl (6.2 kB)\n",
            "Downloading llama_index_indices_managed_llama_cloud-0.6.11-py3-none-any.whl (14 kB)\n",
            "Downloading llama_index_llms_openai-0.3.40-py3-none-any.whl (23 kB)\n",
            "Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl (5.9 kB)\n",
            "Downloading llama_index_program_openai-0.3.1-py3-none-any.whl (5.3 kB)\n",
            "Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl (2.9 kB)\n",
            "Downloading llama_index_readers_file-0.4.7-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl (2.5 kB)\n",
            "Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading aiosqlite-0.21.0-py3-none-any.whl (15 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading llama_parse-0.6.22-py3-none-any.whl (4.9 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading pypdf-5.5.0-py3-none-any.whl (303 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m303.4/303.4 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m98.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading griffe-1.7.3-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m129.3/129.3 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading llama_cloud_services-0.6.22-py3-none-any.whl (37 kB)\n",
            "Downloading llama_cloud-0.1.19-py3-none-any.whl (263 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m263.6/263.6 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: striprtf, filetype, dirtyjson, python-dotenv, pypdf, pinecone-plugin-interface, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mypy-extensions, marshmallow, deprecated, colorama, aiosqlite, typing-inspect, pinecone, nvidia-cusparse-cu12, nvidia-cudnn-cu12, griffe, nvidia-cusolver-cu12, llama-cloud, dataclasses-json, banks, llama-index-core, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-cloud-services, llama-parse, llama-index-multi-modal-llms-openai, llama-index-embeddings-huggingface, llama-index-cli, llama-index-agent-openai, llama-index-readers-llama-parse, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed aiosqlite-0.21.0 banks-2.1.2 colorama-0.4.6 dataclasses-json-0.6.7 deprecated-1.2.18 dirtyjson-1.0.8 filetype-1.2.0 griffe-1.7.3 llama-cloud-0.1.19 llama-cloud-services-0.6.22 llama-index-0.12.36 llama-index-agent-openai-0.4.7 llama-index-cli-0.4.1 llama-index-core-0.12.36 llama-index-embeddings-huggingface-0.5.4 llama-index-embeddings-openai-0.3.1 llama-index-indices-managed-llama-cloud-0.6.11 llama-index-llms-openai-0.3.40 llama-index-multi-modal-llms-openai-0.4.3 llama-index-program-openai-0.3.1 llama-index-question-gen-openai-0.3.0 llama-index-readers-file-0.4.7 llama-index-readers-llama-parse-0.4.0 llama-parse-0.6.22 marshmallow-3.26.1 mypy-extensions-1.1.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pinecone-6.0.2 pinecone-plugin-interface-0.0.7 pypdf-5.5.0 python-dotenv-1.1.0 striprtf-0.0.26 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install llama-index llama-index-core llama-index-embeddings-huggingface pinecone\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pcsk_5VWi9Y_Ejpj6tvvsYkskoiqBL8PyHzoVCUpxdiHs24XyBefeZz6GtEVStgv9SXVXG4ftun\n",
        "# multilingual-chatbot"
      ],
      "metadata": {
        "id": "721Bksv3jVNl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Necessary Modules**"
      ],
      "metadata": {
        "id": "Ofd5p9SLmO8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SimpleDirectoryReader\n",
        "from llama_index.core.node_parser import SimpleNodeParser\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from pinecone import Pinecone"
      ],
      "metadata": {
        "id": "GxL8yyaokMco"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Configure Pinecone**"
      ],
      "metadata": {
        "id": "HSrZak0cmXxX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PINECONE_API_KEY = \"pcsk_5VWi9Y_Ejpj6tvvsYkskoiqBL8PyHzoVCUpxdiHs24XyBefeZz6GtEVStgv9SXVXG4ftun\"\n",
        "PINECONE_ENV = \"us-east-1-aws\"\n",
        "#pinecone_index_name = \"multilingual-chatbot\"\n",
        "\n",
        "# Initialize Pinecone\n",
        "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
        "#index = pc.Index(pinecone_index_name)\n"
      ],
      "metadata": {
        "id": "EYR60KUCkRUq"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pinecone import ServerlessSpec"
      ],
      "metadata": {
        "id": "YXgnJx_IwAgy"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_name = \"mental-health-chatbot\""
      ],
      "metadata": {
        "id": "EZ0m-Psfv7Ek"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete index if exists (optional reset)\n",
        "if index_name in pc.list_indexes().names():\n",
        "    pc.delete_index(index_name)"
      ],
      "metadata": {
        "id": "BTNpNNRkv3en"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Pinecone index with correct dimension (384 for both models)\n",
        "pc.create_index(index_name, dimension=384, metric=\"cosine\",\n",
        "                spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"))\n",
        "index = pc.Index(index_name)"
      ],
      "metadata": {
        "id": "8Ngz6cSTvyou"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load Multilingual PDFs (English + Urdu)**"
      ],
      "metadata": {
        "id": "bEEIc86cmdN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = SimpleDirectoryReader(input_files=[\n",
        "    \"/content/mental_health_en.pdf\",\n",
        "    \"/content/mental_health_ur.pdf\"\n",
        "]).load_data()\n"
      ],
      "metadata": {
        "id": "U0zgZRKxlDSi"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Parse and Chunk Text**"
      ],
      "metadata": {
        "id": "IGwWKoAxmoGr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step A: Chunking Strategy 1 â€“ Fixed-Length Chunking**"
      ],
      "metadata": {
        "id": "GU03nC7zlyPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "node_parser = SimpleNodeParser.from_defaults(chunk_size=512, chunk_overlap=30)\n",
        "nodes = node_parser.get_nodes_from_documents(documents)\n"
      ],
      "metadata": {
        "id": "Q92cXvdmlHcu"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step B: Chunking Strategy 2 â€“ Sentence-Based Chunking**"
      ],
      "metadata": {
        "id": "Hl6NIzWKl321"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "# Sentence-based chunking (e.g., 3 sentences per chunk)\n",
        "def sentence_based_chunking(text, n=3):\n",
        "    sentences = sent_tokenize(text)\n",
        "    chunks = [' '.join(sentences[i:i+n]) for i in range(0, len(sentences), n)]\n",
        "    return chunks\n",
        "\n",
        "# Apply on each document\n",
        "sentence_chunks = []\n",
        "for doc in documents:\n",
        "    text = doc.text\n",
        "    chunks = sentence_based_chunking(text, n=3)\n",
        "    sentence_chunks.extend(chunks)\n",
        "\n",
        "\n",
        "print(f\"Total sentence-based chunks: {len(sentence_chunks)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBZPh4Hrl_Hp",
        "outputId": "94295cf3-544e-478e-94a2-9fbc1657b739"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total sentence-based chunks: 21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Embed with All Three Models And Upload For Fixed Length Chunk**"
      ],
      "metadata": {
        "id": "aIbQMNBTm_JG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Sentence-BERT Embedding and Upload**"
      ],
      "metadata": {
        "id": "jS2h75w8nC9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sbert_model = HuggingFaceEmbedding(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
        "sbert_upsert = []\n",
        "for i, node in enumerate(nodes):\n",
        "    text = node.get_content()\n",
        "    node.embedding = sbert_model.get_text_embedding(text)\n",
        "    node.metadata = {\n",
        "        \"source_text\": text[:300],\n",
        "        \"language\": \"urdu\" if \"ÛÛ’\" in text or \"Ú©Ùˆ\" in text else \"english\",\n",
        "        \"model\": \"sentence-bert\",\n",
        "        \"chunking\": \"fixed\"\n",
        "    }\n",
        "    sbert_upsert.append({\n",
        "        \"id\": f\"sbert-{i}\",\n",
        "        \"values\": node.embedding,\n",
        "        \"metadata\": node.metadata\n",
        "    })\n",
        "index.upsert(vectors=sbert_upsert)\n",
        "print(\"âœ… SBERT embeddings stored successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evsRtUHMlJ5z",
        "outputId": "97774027-ab65-420f-db91-d41a38822c76"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… SBERT embeddings stored successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. DistilBERT Embedding and Upload**"
      ],
      "metadata": {
        "id": "MNV5MTPWnR4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_name2 = \"distilbert-index\""
      ],
      "metadata": {
        "id": "uzAqLS231PCb"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete index if exists (optional reset)\n",
        "if index_name2 in pc.list_indexes().names():\n",
        "    pc.delete_index(index_name2)"
      ],
      "metadata": {
        "id": "o803Lk-o1XVk"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Pinecone index with correct dimension\n",
        "pc.create_index(index_name2, dimension=768, metric=\"cosine\",\n",
        "                spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"))\n",
        "index = pc.Index(index_name2)"
      ],
      "metadata": {
        "id": "PgN5eiZ21t8o"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distil_model = HuggingFaceEmbedding(\"distilbert-base-multilingual-cased\")\n",
        "distil_upsert = []\n",
        "for i, node in enumerate(nodes):\n",
        "    text = node.get_content()\n",
        "    node.embedding = distil_model.get_text_embedding(text)\n",
        "    node.metadata = {\n",
        "        \"source_text\": text[:300],\n",
        "        \"language\": \"urdu\" if \"ÛÛ’\" in text or \"Ú©Ùˆ\" in text else \"english\",\n",
        "        \"model\": \"distilbert\",\n",
        "        \"chunking\": \"fixed\"\n",
        "    }\n",
        "    distil_upsert.append({\n",
        "        \"id\": f\"distil-{i}\",\n",
        "        \"values\": node.embedding,\n",
        "        \"metadata\": node.metadata\n",
        "    })\n",
        "distil_index.upsert(vectors=distil_upsert)\n",
        "print(\"âœ… DistilBERT embeddings stored successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1F9nk1ColMQ1",
        "outputId": "a231b560-e54c-4a7f-d530-b6a32e91c7c3"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name distilbert-base-multilingual-cased. Creating a new one with mean pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… DistilBERT embeddings stored successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Similarity Search Testing Script**"
      ],
      "metadata": {
        "id": "WJOe3Wzv6HSi"
      }
    },
    {
      "source": [
        "def similarity_search(query, model_name=\"sbert\", top_k=3, language=None):\n",
        "    if model_name == \"sbert\":\n",
        "        embedding = sbert_model.get_text_embedding(query)\n",
        "        index = sbert_index\n",
        "    elif model_name == \"distilbert\":\n",
        "        embedding = distil_model.get_text_embedding(query)\n",
        "        index = distil_index\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported model\")\n",
        "\n",
        "    filter_dict = {\"language\": language} if language else None\n",
        "\n",
        "    results = index.query(\n",
        "        vector=embedding,\n",
        "        top_k=top_k,\n",
        "        include_metadata=True,\n",
        "        filter=filter_dict\n",
        "    )\n",
        "\n",
        "    print(f\"\\nğŸ§  Top {top_k} results for query: '{query}' using {model_name.upper()}:\\n\")\n",
        "    for i, match in enumerate(results['matches']):\n",
        "        print(f\"Result #{i+1} | Score: {match['score']:.4f}\")\n",
        "        print(\"Chunk:\", match['metadata']['source_text'])\n",
        "        print(\"-\" * 60)\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "ARHmKKBM6YgG"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sbert_index = pc.Index(\"mental-health-chatbot\")\n",
        "distil_index = pc.Index(\"distilbert-index\")"
      ],
      "metadata": {
        "id": "AsRcHqWi8fp5"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For Sentence-BERT (SBERT)\n",
        "print(\"SBERT -> ENGLISH\")\n",
        "similarity_search(\"What are symptoms of anxiety?\", model_name=\"sbert\", language=\"english\")\n",
        "print(\"SBERT -> URDU\")\n",
        "similarity_search(\"Ø°ÛÙ†ÛŒ Ø¯Ø¨Ø§Ø¤ Ú©ÛŒ Ø¹Ù„Ø§Ù…Ø§Øª Ú©ÛŒØ§ ÛÛŒÚºØŸ\", model_name=\"sbert\", language=\"urdu\")\n",
        "\n",
        "# For DistilBERT\n",
        "print(\"DistilBERT -> ENGLISH\")\n",
        "similarity_search(\"What are symptoms of anxiety?\", model_name=\"distilbert\", language=\"english\")\n",
        "print(\"DistilBERT -> URDU\")\n",
        "similarity_search(\"Ø°ÛÙ†ÛŒ Ø¯Ø¨Ø§Ø¤ Ú©ÛŒ Ø¹Ù„Ø§Ù…Ø§Øª Ú©ÛŒØ§ ÛÛŒÚºØŸ\", model_name=\"distilbert\", language=\"urdu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VSh4NUrozbo",
        "outputId": "87e5a5f7-f77f-41e8-8b03-09e8250ceedc"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SBERT -> ENGLISH\n",
            "\n",
            "ğŸ§  Top 3 results for query: 'What are symptoms of anxiety?' using SBERT:\n",
            "\n",
            "Result #1 | Score: 0.1734\n",
            "Chunk: School-based social and emotional learning programmes are among the most \n",
            "effective promotion strategies for countries at all income levels. \n",
            "Promoting and protecting mental health at work is a growing area of interest and can be \n",
            "supported through legislation and regulation, organizational strategi\n",
            "------------------------------------------------------------\n",
            "Result #2 | Score: 0.1529\n",
            "Chunk: parenting and physical punishment is known to undermine child health and bullying is a leading \n",
            "risk factor for mental health conditions. \n",
            "Protective factors similarly occur throughout our lives and serve to strengthen resilience. They \n",
            "include our individual social and emotional skills and attribut\n",
            "------------------------------------------------------------\n",
            "Result #3 | Score: 0.1386\n",
            "Chunk: Mental health \n",
            " \n",
            "Key facts \n",
            "â€¢ Affordable, effective and feasible strategies exist to promote, protect and restore \n",
            "mental health. \n",
            "â€¢ The need for action on mental health is indisputable and urgent. \n",
            "â€¢ Mental health has intrinsic and instrumental value and is integral to our well-being. \n",
            "â€¢ Mental hea\n",
            "------------------------------------------------------------\n",
            "SBERT -> URDU\n",
            "\n",
            "ğŸ§  Top 3 results for query: 'Ø°ÛÙ†ÛŒ Ø¯Ø¨Ø§Ø¤ Ú©ÛŒ Ø¹Ù„Ø§Ù…Ø§Øª Ú©ÛŒØ§ ÛÛŒÚºØŸ' using SBERT:\n",
            "\n",
            "Result #1 | Score: 0.6443\n",
            "Chunk: ÛÙˆØªØ§ ÛÛ’ ØŒ  Ø¬Ø³ Ù…ÛŒÚº Ù…Ø´Ú©Ù„ Ø§ÙˆØ±  \n",
            "Ù¾Ø±ÛŒØ´Ø§Ù†ÛŒ Ú©ÛŒ Ù…Ø®ØªÙ„Ù ÚˆÚ¯Ø±ÛŒØ§Úº  Ø§ÙˆØ± Ù…Ù…Ú©Ù†Û Ø·ÙˆØ± Ù¾Ø±  Ø¨ÛØª  Ù…Ø®ØªÙ„Ù Ø³Ù…Ø§Ø¬ÛŒ Ø§ÙˆØ± Ø·Ø¨ÛŒ  Ù†ØªØ§Ø¦Ø¬ ÛÙˆØªÛ’  ÛÛŒÚº Û”   \n",
            "Ø°ÛÙ†ÛŒ ØµØ­Øª  Ú©Û’ Ø­Ø§Ù„Ø§Øª  Ù…ÛŒÚº Ø°ÛÙ†ÛŒ  Ø¹ÙˆØ§Ø±Ø¶  Ø§ÙˆØ± Ù†ÙØ³ÛŒØ§ØªÛŒ Ù…Ø¹Ø°ÙˆØ±ÛŒ Ú©Û’ Ø³Ø§ØªÚ¾ Ø³Ø§ØªÚ¾  Ø¯ÛŒÚ¯Ø± Ø°ÛÙ†ÛŒ Ø­Ø§Ù„ØªÛŒÚº Ø´Ø§Ù…Ù„  \n",
            "ÛÛŒÚº Ø¬Ùˆ Ø§ÛÙ… Ù¾Ø±ÛŒØ´Ø§Ù†ÛŒ ØŒ Ú©Ø§Ù… Ú©Ø±Ù†Û’ Ù…ÛŒÚº Ø®Ø±Ø§Ø¨ÛŒ ØŒ ÛŒØ§ Ø®ÙˆØ¯  Ú©Ùˆ Ù†Ù‚ØµØ§Ù†  Ù¾ÛÙ†Ú†Ø§Ù†Û’ Ú©Û’ Ø®Ø·Ø±Û’ Ø³Û’ ÙˆØ§Ø¨Ø³ØªÛ Û\n",
            "------------------------------------------------------------\n",
            "Result #2 | Score: 0.5248\n",
            "Chunk: Ø°ÛÙ†ÛŒ ØµØ­Øª  \n",
            " \n",
            "Ø§ÛÙ… Ø­Ù‚Ø§Ø¦Ù‚   \n",
            "Ø°ÛÙ†ÛŒ ØµØ­Øª  Ú©Ùˆ ÙØ±ÙˆØº Ø¯ÛŒÙ†Û’  ØŒ ØªØ­ÙØ¸ Ø§ÙˆØ± Ø¨Ø­Ø§Ù„ Ú©Ø±Ù†Û’ Ú©Û’ Ù„ÛŒÛ’ Ø³Ø³ØªÛŒ ØŒ Ù…ÙˆØ«Ø± Ø§ÙˆØ± Ù‚Ø§Ø¨Ù„ Ø¹Ù…Ù„ Ø­Ú©Ù…Øª  Ø¹Ù…Ù„ÛŒ  \n",
            "Ù…ÙˆØ¬ÙˆØ¯  ÛÛŒÚº Û”   \n",
            " â€¢Ø°ÛÙ†ÛŒ  ØµØ­Øª  Ù¾Ø± Ú©Ø§Ø±Ø±ÙˆØ§Ø¦ÛŒ  Ú©ÛŒ Ø¶Ø±ÙˆØ±Øª  Ù†Ø§Ù‚Ø§Ø¨Ù„ ØªØ±Ø¯ÛŒØ¯   Ø§ÙˆØ± ÙÙˆØ±ÛŒ ÛÛ’ Û”   \n",
            " â€¢Ø°ÛÙ†ÛŒ  ØµØ­Øª  Ú©ÛŒ Ø§Ù†Ø¯Ø±ÙˆÙ†ÛŒ  Ø§ÙˆØ± Ø³Ø§Ø²Ú¯Ø§Ø± Ù‚Ø¯Ø± ÛÛ’ Ø§ÙˆØ± ÛŒÛ  ÛÙ…Ø§Ø±ÛŒ ÙÙ„Ø§Ø­ Ùˆ  Ø¨ÛØ¨ÙˆØ¯  Ú©Ø§  Ù„Ø§Ø²Ù…ÛŒ Ø­ØµÛ ÛÛ’ Û”   \n",
            " â€¢Ø°ÛÙ†ÛŒ\n",
            "------------------------------------------------------------\n",
            "Result #3 | Score: 0.5166\n",
            "Chunk: ØŒ \n",
            "Ø°ÛÙ†ÛŒ ØµØ­Øª  Ú©Û’  Ø¨Ø§ÛÙ…ÛŒ ØªØ¹Ø§Ù…Ù„ Ú©Û’ ØªØ¹ÛŒÙ† Ú©Ù†Ù†Ø¯Ú¯Ø§Ù† Ø°ÛÙ†ÛŒ  ØµØ­Øª  Ú©Ùˆ Ø¨Ú‘Ú¾Ø§Ù†Û’  ÛŒØ§ Ú©Ù…Ø²ÙˆØ± Ú©Ø±Ù†Û’ Ú©Ø§ Ú©Ø§Ù… Ú©Ø±ØªÛ’  \n",
            "ÛÛŒÚº Û”   \n",
            "Ø°ÛÙ†ÛŒ ØµØ­Øª  Ú©Ø§ ÙØ±ÙˆØº Ø§ÙˆØ± Ø±ÙˆÚ© ØªÚ¾Ø§Ù…   \n",
            "ÙØ±ÙˆØº Ø§ÙˆØ± Ø±ÙˆÚ© ØªÚ¾Ø§Ù… Ú©ÛŒ Ù…Ø¯Ø§Ø®Ù„Øª  Ø°ÛÙ†ÛŒ ØµØ­Øª  Ú©Û’ Ø§Ù†ÙØ±Ø§Ø¯ÛŒ ØŒ Ø³Ù…Ø§Ø¬ÛŒ Ø§ÙˆØ± Ø³Ø§Ø®ØªÛŒ ØªØ¹ÛŒÙ† Ú©Ù†Ù†Ø¯Ú¯Ø§Ù† Ú©ÛŒ Ø´Ù†Ø§Ø®Øª  \n",
            "Ú©Ø±Ú©Û’ Ú©Ø§Ù… Ú©Ø±ØªÛŒ ÛÛ’ ØŒ Ø§ÙˆØ±  Ù¾Ú¾Ø± Ø®Ø·Ø±Ø§Øª  Ú©Ùˆ Ú©Ù… Ú©Ø±Ù†Û’ ØŒ Ù„Ú†Ú© Ù¾ÛŒØ¯Ø§ Ú©Ø±Ù†Û’ Ø§ÙˆØ± Ø°ÛÙ†ÛŒ\n",
            "------------------------------------------------------------\n",
            "DistilBERT -> ENGLISH\n",
            "\n",
            "ğŸ§  Top 3 results for query: 'What are symptoms of anxiety?' using DISTILBERT:\n",
            "\n",
            "Result #1 | Score: 0.6493\n",
            "Chunk: Mental health \n",
            " \n",
            "Key facts \n",
            "â€¢ Affordable, effective and feasible strategies exist to promote, protect and restore \n",
            "mental health. \n",
            "â€¢ The need for action on mental health is indisputable and urgent. \n",
            "â€¢ Mental health has intrinsic and instrumental value and is integral to our well-being. \n",
            "â€¢ Mental hea\n",
            "------------------------------------------------------------\n",
            "Result #2 | Score: 0.5997\n",
            "Chunk: parenting and physical punishment is known to undermine child health and bullying is a leading \n",
            "risk factor for mental health conditions. \n",
            "Protective factors similarly occur throughout our lives and serve to strengthen resilience. They \n",
            "include our individual social and emotional skills and attribut\n",
            "------------------------------------------------------------\n",
            "Result #3 | Score: 0.5841\n",
            "Chunk: Mental health care and treatment \n",
            "In the context of national efforts to strengthen mental health, it is vital to not only protect and \n",
            "promote the mental well-being of all, but also to address the needs of people with mental health \n",
            "conditions. \n",
            "This should be done through community-based mental hea\n",
            "------------------------------------------------------------\n",
            "DistilBERT -> URDU\n",
            "\n",
            "ğŸ§  Top 3 results for query: 'Ø°ÛÙ†ÛŒ Ø¯Ø¨Ø§Ø¤ Ú©ÛŒ Ø¹Ù„Ø§Ù…Ø§Øª Ú©ÛŒØ§ ÛÛŒÚºØŸ' using DISTILBERT:\n",
            "\n",
            "Result #1 | Score: 0.8320\n",
            "Chunk: Ø°ÛÙ†ÛŒ ØµØ­Øª  \n",
            " \n",
            "Ø§ÛÙ… Ø­Ù‚Ø§Ø¦Ù‚   \n",
            "Ø°ÛÙ†ÛŒ ØµØ­Øª  Ú©Ùˆ ÙØ±ÙˆØº Ø¯ÛŒÙ†Û’  ØŒ ØªØ­ÙØ¸ Ø§ÙˆØ± Ø¨Ø­Ø§Ù„ Ú©Ø±Ù†Û’ Ú©Û’ Ù„ÛŒÛ’ Ø³Ø³ØªÛŒ ØŒ Ù…ÙˆØ«Ø± Ø§ÙˆØ± Ù‚Ø§Ø¨Ù„ Ø¹Ù…Ù„ Ø­Ú©Ù…Øª  Ø¹Ù…Ù„ÛŒ  \n",
            "Ù…ÙˆØ¬ÙˆØ¯  ÛÛŒÚº Û”   \n",
            " â€¢Ø°ÛÙ†ÛŒ  ØµØ­Øª  Ù¾Ø± Ú©Ø§Ø±Ø±ÙˆØ§Ø¦ÛŒ  Ú©ÛŒ Ø¶Ø±ÙˆØ±Øª  Ù†Ø§Ù‚Ø§Ø¨Ù„ ØªØ±Ø¯ÛŒØ¯   Ø§ÙˆØ± ÙÙˆØ±ÛŒ ÛÛ’ Û”   \n",
            " â€¢Ø°ÛÙ†ÛŒ  ØµØ­Øª  Ú©ÛŒ Ø§Ù†Ø¯Ø±ÙˆÙ†ÛŒ  Ø§ÙˆØ± Ø³Ø§Ø²Ú¯Ø§Ø± Ù‚Ø¯Ø± ÛÛ’ Ø§ÙˆØ± ÛŒÛ  ÛÙ…Ø§Ø±ÛŒ ÙÙ„Ø§Ø­ Ùˆ  Ø¨ÛØ¨ÙˆØ¯  Ú©Ø§  Ù„Ø§Ø²Ù…ÛŒ Ø­ØµÛ ÛÛ’ Û”   \n",
            " â€¢Ø°ÛÙ†ÛŒ\n",
            "------------------------------------------------------------\n",
            "Result #2 | Score: 0.8197\n",
            "Chunk: ÛÙˆØªØ§ ÛÛ’ ØŒ  Ø¬Ø³ Ù…ÛŒÚº Ù…Ø´Ú©Ù„ Ø§ÙˆØ±  \n",
            "Ù¾Ø±ÛŒØ´Ø§Ù†ÛŒ Ú©ÛŒ Ù…Ø®ØªÙ„Ù ÚˆÚ¯Ø±ÛŒØ§Úº  Ø§ÙˆØ± Ù…Ù…Ú©Ù†Û Ø·ÙˆØ± Ù¾Ø±  Ø¨ÛØª  Ù…Ø®ØªÙ„Ù Ø³Ù…Ø§Ø¬ÛŒ Ø§ÙˆØ± Ø·Ø¨ÛŒ  Ù†ØªØ§Ø¦Ø¬ ÛÙˆØªÛ’  ÛÛŒÚº Û”   \n",
            "Ø°ÛÙ†ÛŒ ØµØ­Øª  Ú©Û’ Ø­Ø§Ù„Ø§Øª  Ù…ÛŒÚº Ø°ÛÙ†ÛŒ  Ø¹ÙˆØ§Ø±Ø¶  Ø§ÙˆØ± Ù†ÙØ³ÛŒØ§ØªÛŒ Ù…Ø¹Ø°ÙˆØ±ÛŒ Ú©Û’ Ø³Ø§ØªÚ¾ Ø³Ø§ØªÚ¾  Ø¯ÛŒÚ¯Ø± Ø°ÛÙ†ÛŒ Ø­Ø§Ù„ØªÛŒÚº Ø´Ø§Ù…Ù„  \n",
            "ÛÛŒÚº Ø¬Ùˆ Ø§ÛÙ… Ù¾Ø±ÛŒØ´Ø§Ù†ÛŒ ØŒ Ú©Ø§Ù… Ú©Ø±Ù†Û’ Ù…ÛŒÚº Ø®Ø±Ø§Ø¨ÛŒ ØŒ ÛŒØ§ Ø®ÙˆØ¯  Ú©Ùˆ Ù†Ù‚ØµØ§Ù†  Ù¾ÛÙ†Ú†Ø§Ù†Û’ Ú©Û’ Ø®Ø·Ø±Û’ Ø³Û’ ÙˆØ§Ø¨Ø³ØªÛ Û\n",
            "------------------------------------------------------------\n",
            "Result #3 | Score: 0.8175\n",
            "Chunk: Ù…Ø±Ø§Ø­Ù„ Ù…ÛŒÚº Ø®ÙˆØ¯  Ú©Ùˆ Ø¸Ø§ÛØ± Ú©Ø±  Ø³Ú©ØªÛ’ ÛÛŒÚº ØŒ Ù„ÛŒÚ©Ù† ÙˆÛ Ø¬Ùˆ Ù†Ø´ÙˆÙˆÙ†Ù…Ø§ Ú©Û’ Ù„Ø­Ø§Ø¸ Ø³Û’  \n",
            "Ø­Ø³Ø§Ø³ Ø§Ø¯ÙˆØ§Ø± ØŒ Ø®Ø§Øµ  Ø·ÙˆØ± Ù¾Ø± Ø§Ø¨ØªØ¯Ø§Ø¦ÛŒ Ø¨Ú†Ù¾Ù† Ú©Û’ Ø¯ÙˆØ±Ø§Ù†  ÛÙˆØªÛ’ ÛÛŒÚº ØŒ Ø®Ø§Øµ  Ø·ÙˆØ± Ù¾Ø±  Ù†Ù‚ØµØ§Ù† Ø¯Û ÛÙˆØªÛ’ ÛÛŒÚº Û”\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6J8r85ZM7l7T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}